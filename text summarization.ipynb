{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5460ec76-d40c-471a-b1cc-b37bb4a1704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5b163a-a6a9-49fe-b7b5-f3dd700ef801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\AMIRTHA\n",
      "[nltk_data]     VARSHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\AMIRTHA\n",
      "[nltk_data]     VARSHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bada22-25fd-43d6-93c2-ac721f87a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\amirtha varshini\\downloads\\anaconda files\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895de4ea-60d0-40d6-9265-89cb63a1a5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quantum', 'comput', 'emerg', 'field', 'har', 'principl', 'quantum', 'mechan', 'process', 'inform', 'way', 'classic', 'comput', '.']\n",
      "['unlik', 'classic', 'bit', 'repres', 'either', '0', '1', ',', 'quantum', 'bit', 'qubit', 'exist', 'multipl', 'state', 'simultan', 'due', 'superposit', '.']\n",
      "['properti', 'allow', 'quantum', 'comput', 'perform', 'complex', 'calcul', 'exponenti', 'faster', 'classic', 'comput', 'certain', 'task', '.']\n",
      "['potenti', 'applic', 'quantum', 'comput', 'vast', 'includ', 'cryptographi', ',', 'optim', 'problem', ',', 'drug', 'discoveri', '.']\n",
      "['quantum', 'algorithm', 'shor', \"'s\", 'algorithm', 'potenti', 'break', 'classic', 'encrypt', 'method', ',', 'pose', 'challeng', 'opportun', 'cybersecur', '.']\n",
      "['optim', 'problem', ',', 'rout', 'plan', 'resourc', 'alloc', ',', 'tackl', 'effici', 'use', 'quantum', 'anneal', 'quantum', 'optim', 'techniqu', '.']\n",
      "['field', 'quantum', 'chemistri', ',', 'quantum', 'comput', 'simul', 'behavior', 'molecul', 'materi', 'unpreced', 'accuraci', '.']\n",
      "['capabl', 'could', 'revolution', 'drug', 'discoveri', 'acceler', 'process', 'identifi', 'new', 'pharmaceut', 'compound', 'understand', 'molecular', 'interact', '.']\n",
      "['howev', ',', 'build', 'practic', 'quantum', 'comput', 'face', 'signific', 'challeng', ',', 'includ', 'decoher', ',', 'error', 'correct', ',', 'scale', 'qubit', 'count', '.']\n",
      "['decoher', 'refer', 'loss', 'quantum', 'coher', ',', 'limit', 'time', 'qubit', 'maintain', 'superposit', 'entangl', '.']\n",
      "['error', 'correct', 'techniqu', 'quantum', 'error', 'correct', 'code', 'crucial', 'preserv', 'quantum', 'state', 'nois', 'error', '.']\n",
      "['despit', 'challeng', ',', 'major', 'advanc', 'made', 'research', 'institut', 'tech', 'compani', 'worldwid', '.']\n",
      "['compani', 'like', 'ibm', ',', 'googl', ',', 'microsoft', 'activ', 'develop', 'quantum', 'hardwar', 'softwar', 'platform', 'explor', 'full', 'potenti', 'quantum', 'comput', '.']\n",
      "['field', 'continu', 'evolv', ',', 'quantum', 'comput', 'hold', 'promis', 'solv', 'complex', 'problem', 'current', 'intract', 'classic', 'comput', '.']\n",
      "Summary:\n",
      "Optimization problems, such as route planning and resource allocation, can be tackled more efficiently using quantum annealing and other quantum optimization techniques. Error correction techniques such as quantum error correction codes are crucial for preserving quantum states against noise and errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\AMIRTHA\n",
      "[nltk_data]     VARSHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\AMIRTHA\n",
      "[nltk_data]     VARSHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "   \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    \n",
    " \n",
    "    porter = PorterStemmer()\n",
    "    words = [porter.stem(word) for word in words]\n",
    "    print(words)\n",
    "    return(words)\n",
    "\n",
    "def summarize(text, summary_length):\n",
    "    tokenized_text = sent_tokenize(text)\n",
    "    preprocessed_text = [preprocess_text(sent) for sent in tokenized_text]\n",
    "    \n",
    "  \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform([' '.join(sent) for sent in preprocessed_text])\n",
    "    \n",
    "\n",
    "    sentence_scores = [] \n",
    "    for i in range(len(tokenized_text)):\n",
    "        score = sum(tfidf_matrix[i, tfidf.vocabulary_.get(word, 0)] for word in preprocessed_text[i])\n",
    "        sentence_scores.append((i, score))\n",
    "    \n",
    "   \n",
    "    selected_sentences = sorted(sentence_scores, key=lambda x: x[1], reverse=True)[:summary_length]\n",
    "    selected_sentences = sorted(selected_sentences, key=lambda x: x[0])  \n",
    "    \n",
    "\n",
    "    summary = ' '.join([tokenized_text[i] for i, score in selected_sentences])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "Quantum computing is an emerging field that harnesses the principles of quantum mechanics to process information in ways that classical computers cannot. Unlike classical bits that represent either 0 or 1, quantum bits or qubits can exist in multiple states simultaneously due to superposition. This property allows quantum computers to perform complex calculations exponentially faster than classical computers for certain tasks.\n",
    "The potential applications of quantum computing are vast and include cryptography, optimization problems, and drug discovery. Quantum algorithms such as Shor's algorithm have the potential to break classical encryption methods, posing both a challenge and an opportunity for cybersecurity. Optimization problems, such as route planning and resource allocation, can be tackled more efficiently using quantum annealing and other quantum optimization techniques.\n",
    "In the field of quantum chemistry, quantum computers can simulate the behavior of molecules and materials with unprecedented accuracy. This capability could revolutionize drug discovery by accelerating the process of identifying new pharmaceutical compounds and understanding molecular interactions.\n",
    "However, building practical quantum computers faces significant challenges, including decoherence, error correction, and scaling qubit counts. Decoherence refers to the loss of quantum coherence, which limits the time qubits can maintain superposition and entanglement. Error correction techniques such as quantum error correction codes are crucial for preserving quantum states against noise and errors.\n",
    "Despite these challenges, major advances are being made by research institutions and tech companies worldwide. Companies like IBM, Google, and Microsoft are actively developing quantum hardware and software platforms to explore the full potential of quantum computing. As the field continues to evolve, quantum computing holds promise for solving complex problems that are currently intractable with classical computers.\n",
    "\"\"\"\n",
    "\n",
    "summary_length = 2\n",
    "\n",
    "summary = summarize(text, summary_length)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a21ca62-ec0a-4c4c-83d9-4cf36a5b1951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d07d7-7bdb-4383-a79a-104606aecd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "The\n",
    "\n",
    "the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7d8fa3-3c17-4500-ad67-88ef71a3353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 4), (4, 7), (2, 4), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "arr = [(1, 2), (8, 4), (2, 4), (4, 7)] \n",
    "arr = sorted(arr, key = lambda y : y[0], reverse = True)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522d5ed-aca1-4acb-a89c-88eb99c6ec45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550464d-11c5-41f1-9b88-11c386da4fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
